{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>.container { width:100% !important; }</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Use apropriate metric and \\*Classifier classes instead of \\*Regressor\n",
    "\n",
    "Good guide to classical problem \n",
    "\n",
    "https://www.kaggle.com/harunshimanto/titanic-solution-for-beginner-s-guide\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'images', 'target', 'target_names']\n",
      " digits.data.shape: (1797, 64) \n",
      " digits.images.shape: (1797, 8, 8) \n",
      " digits.target.shape: (1797,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "print(dir(digits))\n",
    "print(' digits.data.shape: %s \\n digits.images.shape: %s \\n digits.target.shape: %s \\n' % (digits.data.shape, digits.images.shape, digits.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "print(X.shape)\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        37\n",
      "          1       0.91      0.98      0.94        43\n",
      "          2       0.98      0.95      0.97        44\n",
      "          3       0.93      0.96      0.95        45\n",
      "          4       0.95      0.97      0.96        38\n",
      "          5       0.96      0.98      0.97        48\n",
      "          6       1.00      0.96      0.98        52\n",
      "          7       0.98      0.98      0.98        48\n",
      "          8       0.98      0.90      0.93        48\n",
      "          9       0.94      0.96      0.95        47\n",
      "\n",
      "avg / total       0.96      0.96      0.96       450\n",
      "\n",
      "[[36  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 42  0  0  1  0  0  0  0  0]\n",
      " [ 1  0 42  0  0  0  0  0  1  0]\n",
      " [ 0  0  1 43  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 37  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 47  0  0  0  1]\n",
      " [ 0  2  0  0  0  0 50  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 47  0  0]\n",
      " [ 0  2  0  2  0  0  0  0 43  1]\n",
      " [ 0  0  0  1  0  1  0  0  0 45]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.virtualenvs/ML/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgb_model = LGBMClassifier()\n",
    "lgb_model.fit(train_X, train_y)\n",
    "lgb_preds = lgb_model.predict(val_X)\n",
    "# https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "print(metrics.classification_report(val_y, lgb_preds))\n",
    "print(metrics.confusion_matrix(val_y, lgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot last 4 predictions\n",
    "images_and_predictions = list(zip(val_X, lgb_preds))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape((8,8)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try own image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIL library\n",
    "\n",
    "Various functions to work with images\n",
    "\n",
    "https://pillow.readthedocs.io/en/5.1.x/\n",
    "\n",
    "```\n",
    "pip install Pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import numpy as np\n",
    "\n",
    "def loadAndFitImage(im):\n",
    "    # trim borders\n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = diff.getbbox()\n",
    "    result = im\n",
    "    if bbox:\n",
    "        result = im.crop(bbox)\n",
    "    # convert to greyscale and resize\n",
    "    result = result.convert('L')\n",
    "    result.thumbnail((8, 8))\n",
    "    # add borders again to fit to 8*8\n",
    "    if result.width < 8 or result.height < 8:\n",
    "        bg = Image.new('L', (8, 8), 'white')\n",
    "        xCoord = (8 - result.width) // 2\n",
    "        yCoord = (8 - result.height) // 2\n",
    "        bg.paste(result, (xCoord, yCoord))\n",
    "        result = bg\n",
    "    return result\n",
    "\n",
    "def preprocessImage(fileName):\n",
    "    imSample = loadAndFitImage(Image.open(fileName))\n",
    "    imAsVector = 255 - np.array(imSample).reshape((1, -1)).astype('float')\n",
    "    #scale\n",
    "    return minmax_scale(imAsVector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5bab7fd5c0>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testImages = [preprocessImage('digit_8.png'), preprocessImage('digit_six.png')]\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(testImages[0].reshape((8, 8)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(testImages[1].reshape((8, 8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train on all available data\n",
    "#scale dataset in the same way as our own sample\n",
    "scaledX = minmax_scale(X)\n",
    "finalModel = LGBMClassifier()\n",
    "finalModel.fit(scaledX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.virtualenvs/ML/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 3])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "finalModel.predict(testImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>bt not his girlfrnd... G o o d n i g h t . . .@\"</td>\n",
       "      <td>MK17 92H. 450Ppw 16\"</td>\n",
       "      <td>GNT:-)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          v1                      v2  \\\n",
       "count   5572                    5572   \n",
       "unique     2                    5169   \n",
       "top      ham  Sorry, I'll call later   \n",
       "freq    4825                      30   \n",
       "\n",
       "                                               Unnamed: 2  \\\n",
       "count                                                  50   \n",
       "unique                                                 43   \n",
       "top      bt not his girlfrnd... G o o d n i g h t . . .@\"   \n",
       "freq                                                    3   \n",
       "\n",
       "                   Unnamed: 3 Unnamed: 4  \n",
       "count                      12          6  \n",
       "unique                     10          5  \n",
       "top      MK17 92H. 450Ppw 16\"    GNT:-)\"  \n",
       "freq                        2          2  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "spamata = pd.read_csv('./spam.csv', encoding='latin1')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tf–idf wiki](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "[Scikit docs](http://scikit-learn.org/stable/modules/feature_extraction.html#applications-and-examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.virtualenvs/ML/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9770279971284996"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#encode categories\n",
    "y = data['v1'].replace(['ham','spam'],[0,1]).values\n",
    "#vectorize text using tf-idf\n",
    "X_text = data['v2'].values\n",
    "vectorizer = TfidfVectorizer(stop_words='english', analyzer='word')\n",
    "X = vectorizer.fit_transform(X_text).toarray()\n",
    "#split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "#build model\n",
    "spamModel = LGBMClassifier()\n",
    "spamModel.fit(X_train, y_train)\n",
    "#validation score\n",
    "spamPred = spamModel.predict(X_test)\n",
    "accuracy_score(y_test, spamPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179, 8404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artem/.virtualenvs/ML/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use model\n",
    "spamText = 'URGENT! We are trying to contact U.Todays draw shows that you have won a 2000 prize GUARANTEED. Call 090 5809 4507 from land line. Claim 3030. Valid 12hrs only'\n",
    "goodText = 'Good evening, our hotel haven\\'t got bar. There is a restaurant next door, which belongs to us. You can either attend for dinner in there or order room service from menu of restaurant. Kind regards'\n",
    "#vectorize our samples !!!using the same vectorizer!!!\n",
    "testVector = vectorizer.transform([spamText, goodText]).toarray()\n",
    "#get results\n",
    "spamModel.predict(testVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Examples:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html\n",
    "\n",
    "https://dzone.com/articles/cluster-image-with-k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
