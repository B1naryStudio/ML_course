{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network, CNN, ConvNet\n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Extracts **translation invariant** features from images (or other sequencial data: video, sound, etc). Each next layer learns more abstract patterns. Basically consists of stack of convolutiuonal layer followed by maxpooling layer, or instead of maxpooling layer next conv layer must have higher stride parameter.\n",
    "\n",
    "### Convolution\n",
    "![Convolution](https://i.stack.imgur.com/GvsBA.jpg)\n",
    "\n",
    "![Work Animation](https://cdn-images-1.medium.com/max/1600/1*_34EtrgYk6cQxlJ2br51HQ.gif)\n",
    "\n",
    "### Maxpooling\n",
    "![Maxpooling](https://qph.ec.quoracdn.net/main-qimg-8afedfb2f82f279781bfefa269bc6a90)\n",
    "\n",
    "### Visualisation CNN internals\n",
    "\n",
    "[How it sees. Filters visualisations](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html)\n",
    "\n",
    "**Recognition heat-map**\n",
    "![heat-map](http://cs231n.github.io/assets/cnnvis/occlude.jpeg)\n",
    "\n",
    "http://cs231n.github.io/understanding-cnn/\n",
    "\n",
    "http://yeephycho.github.io/2016/08/31/A-reminder-of-algorithms-in-Convolutional-Neural-Networks-and-their-influences-III/\n",
    "\n",
    "[Keras example](https://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/index.html)\n",
    "\n",
    "## Depthwise separable convolution\n",
    "\n",
    "Drop-in replacement for regular ConvNet. Faster and more efficient.\n",
    "\n",
    "https://keras.io/layers/convolutional/#separableconv2d\n",
    "\n",
    "## Capsule neural network\n",
    "\n",
    "Must be better than ConvNet but it is fresh and isn't investigated well.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Capsule_neural_network\n",
    "\n",
    "https://github.com/XifengGuo/CapsNet-Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural network, RNN\n",
    "\n",
    "To process timeseries (sound, text, weather data, etc) where the recent past is more important than the distant past. Has an internal loop to maintain the state over samples series. **Simple RNN** suffers from vanishing gradients on long series. **LSTM** is much better but more computationly complex, **GRU** is lighter but not as good as LSTM and probably better for smaller datasets.\n",
    "### Simple RNN\n",
    "![rnn](./img/rnn.png)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Long_short-term_memory\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gated_recurrent_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text encoding\n",
    "Deep learning tends to don't use \"bag of n-grams\" representation as it breaks words order. Use one-hot encoding or word embeddings.\n",
    "### Word embedding space\n",
    "\n",
    "![embedding space](https://www.researchgate.net/profile/Miao_Fan4/publication/274263375/figure/fig1/AS:294820271673351@1447302038942/The-result-of-vector-calculation-in-the-word-embedding-space-v-M-adrid-v-Spain-v-F.png)\n",
    "\n",
    "https://machinelearningmastery.com/what-are-word-embeddings/\n",
    "\n",
    "https://keras.io/layers/embeddings/\n",
    "\n",
    "### Some public pretrained word embeddings\n",
    "\n",
    "https://code.google.com/archive/p/word2vec/\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "Deep network learned on a huge dataset is highly generalized, and it is possible to reuse it. \n",
    "\n",
    "https://keras.io/applications/\n",
    "\n",
    "1. Add your custom network on top of an already-trained base network.\n",
    "2. Freeze the base network.\n",
    "3. Train the part you added.\n",
    "4. Unfreeze some layers in the base network. (Fine-tuning)\n",
    "5. Jointly train both these layers and the part you added. (Fine-tuning)\n",
    "\n",
    "Usually works better for ConvNets because visual patterns space are common for all datasets unlike, for example, text embeddings space. However, it is possible to load pretrained embeddings into Keras Embedding() layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras functional API\n",
    "To implement non-sequential models (multiple inputs, outputs, shared layers, residual connections, etc)\n",
    "\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative models\n",
    "\n",
    "### Style transfer\n",
    "![style transfer example](https://cdn-images-1.medium.com/max/1600/1*MAjeF5fiRosZP6PMtAQp_Q.jpeg)\n",
    "\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.3-neural-style-transfer.ipynb\n",
    "\n",
    "### Image generation\n",
    "\n",
    "Learn latent space from dataset then sample point from it and map to image space\n",
    "\n",
    "#### Variational autoencoders, VAE\n",
    "Learns continuous latent space, can be used for semantic editing.\n",
    "\n",
    "![Smile](./img/tom_white_smile.png)\n",
    "\n",
    "![Replace](./img/tom_white_replace.png)\n",
    "\n",
    "http://kvfrans.com/variational-autoencoders-explained/\n",
    "\n",
    "#### Generative adversarial networks, GAN\n",
    "Consists of two networks: expert and forger, expert learns to detect a forgery, and forger learns to fool an expert. Hard to teach, doesn't learn continuous space.\n",
    "\n",
    "http://www.miketyka.com/?s=faces\n",
    "\n",
    "**GAN** and **VAE** can be combined. \n",
    "\n",
    "https://habr.com/post/331382/\n",
    "\n",
    "### LSTM to generate sequences (text, notes, etc)\n",
    "Model learns to predict next token in sequence.\n",
    "\n",
    "![lstm generative](./img/lstm_gen.png)\n",
    "\n",
    "https://machinelearningmastery.com/gentle-introduction-generative-long-short-term-memory-networks/\n",
    "\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-network, DQN (Deep reinforcement learning)\n",
    "\n",
    "Q function evaluates reward by given state and action. Use neural network as Q function.\n",
    "\n",
    "https://becominghuman.ai/lets-build-an-atari-ai-part-0-intro-to-rl-9b2c5336e0ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI gym\n",
    "Provides easy to use environment to develop and test algorithms (agents) playing games.\n",
    "\n",
    "[Docs](https://gym.openai.com/docs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T2T tool\n",
    "\n",
    "https://github.com/tensorflow/tensor2tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV\n",
    "\n",
    "Computer vision library, actually it is not fully powered by ML but very useful in video and image processing tasks.\n",
    "\n",
    "http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html\n",
    "\n",
    "https://realpython.com/face-recognition-with-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memo\n",
    "\n",
    "### Last layer activation and loss\n",
    "| Problem type                            | Last-layer activation | Loss function              |\n",
    "| :-------------------------------------- | --------------------- | -------------------------- |\n",
    "| Binary classification                   | sigmoid\t              | binary_crossentropy        |\n",
    "| Multiclass, single-label classification | softmax               |\tcategorical_crossentropy   |\n",
    "| Multiclass, multilabel classification\t  | sigmoid\t              | binary_crossentropy        |\n",
    "| Regression to arbitrary values\t      | None                  |\tmse                        |\n",
    "| Regression to values between 0 and 1    |\tsigmoid\t              | mse or binary_crossentropy |\n",
    "\n",
    "### Choose layer architecture\n",
    "- **Vector data** Densely connected network (Dense layers).\n",
    "\n",
    "- **Image data** 2D convnets.\n",
    "\n",
    "- **Sound data (for example, waveform)** Either 1D convnets (preferred) or RNNs.\n",
    "\n",
    "- **Text data** Either 1D convnets (preferred) or RNNs.\n",
    "\n",
    "- **Timeseries data** Either RNNs (preferred) or 1D convnets.\n",
    "\n",
    "- **Other types of sequence data** Either RNNs or 1D convnets. Prefer RNNs if data ordering is strongly meaningful (for example, for timeseries, but not for text).\n",
    "\n",
    "- **Video data** Either 3D convnets (if you need to capture motion effects) or a combination of a frame-level 2D convnet for feature extraction followed by either an RNN or a 1D convnet to process the resulting sequences.\n",
    "\n",
    "- **Volumetric data** 3D convnets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To learn more\n",
    "\n",
    "https://www.manning.com/books/deep-learning-with-python\n",
    "\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "\n",
    "https://www.deeplearning.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
